{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_t0XMYQac2M",
        "outputId": "088893bb-f08c-4399-d435-baf205dad82e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sgfmill\n",
            "  Downloading sgfmill-1.1.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Downloading sgfmill-1.1.1-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: sgfmill\n",
            "Successfully installed sgfmill-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sgfmill numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sgfmill import sgf, boards\n",
        "\n",
        "# Kích thước bàn cờ\n",
        "BOARD_SIZE = 19\n",
        "# Số lượng history planes (8 cho ta + 8 cho địch = 16)\n",
        "HISTORY_LENGTH = 8\n",
        "\n",
        "def make_input_planes(game_state, color, history_states):\n",
        "    \"\"\"\n",
        "    Tạo ra tensor 17x19x19\n",
        "    color: 'b' hoặc 'w' (người đang đi nước này)\n",
        "    history_states: List các trạng thái bàn cờ trước đó\n",
        "    \"\"\"\n",
        "    features = np.zeros((17, BOARD_SIZE, BOARD_SIZE), dtype=np.float32)\n",
        "\n",
        "    current_player_color = color\n",
        "    opponent_color = 'w' if color == 'b' else 'b'\n",
        "\n",
        "    # --- 16 Kênh Lịch sử (8 Ta + 8 Địch) ---\n",
        "    # Lấy tối đa 8 trạng thái gần nhất, nếu không đủ thì padding số 0\n",
        "    recent_states = history_states[-HISTORY_LENGTH:]\n",
        "    # Đảo ngược để trạng thái mới nhất nằm đầu\n",
        "    recent_states = recent_states[::-1]\n",
        "\n",
        "    for i, state in enumerate(recent_states):\n",
        "        # Kênh quân Ta (0, 2, 4...)\n",
        "        features[i] = (state == current_player_color).astype(np.float32)\n",
        "        # Kênh quân Địch (8, 9, 10...) -> Logic trong AlphaGo Zero xếp xen kẽ hoặc tách khối\n",
        "        # Ở đây ta xếp: 8 kênh Ta trước, 8 kênh Địch sau cho dễ hình dung\n",
        "        features[i + 8] = (state == opponent_color).astype(np.float32)\n",
        "\n",
        "    # --- Kênh thứ 17: Màu quân (Ai đi lượt này?) ---\n",
        "    # Nếu Đen đi: toàn số 1. Nếu Trắng đi: toàn số 0.\n",
        "    if color == 'b':\n",
        "        features[16] = np.ones((BOARD_SIZE, BOARD_SIZE), dtype=np.float32)\n",
        "\n",
        "    return features\n",
        "\n",
        "def parse_move(move_coords, board_size=19):\n",
        "    \"\"\"Chuyển tọa độ (row, col) thành số nguyên 0-360. Pass là 361\"\"\"\n",
        "    if move_coords is None:\n",
        "        return board_size * board_size # Nước Pass\n",
        "    row, col = move_coords\n",
        "    return row * board_size + col"
      ],
      "metadata": {
        "id": "QU1CQJ2kahla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58ae13f1",
        "outputId": "2e7f62d6-1b22-4f56-daf9-1e77fe69022f"
      },
      "source": [
        "get_ipython().system('sudo apt-get update')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [Connecting to security.ub\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,153 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,835 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,222 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,008 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,488 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,596 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,876 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,290 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,539 kB]\n",
            "Fetched 37.5 MB in 6s (6,801 kB/s)\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e07127e3",
        "outputId": "10e1209c-fc7f-43bf-eb33-2278d10dbf27"
      },
      "source": [
        "get_ipython().system('sudo apt-get install -y p7zip-full')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e25472de"
      },
      "source": [
        "get_ipython().system('mkdir -p Datasets')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fBo1n8SNv5x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "817f0427",
        "outputId": "e2672c7d-cea3-4c26-dd9e-4de8e3f400dc"
      },
      "source": [
        "import glob\n",
        "\n",
        "# Find all .7z files in the current directory\n",
        "seven_zip_files = glob.glob('*.7z')\n",
        "\n",
        "# Extract each .7z file into the Datasets directory\n",
        "for file in seven_zip_files:\n",
        "    print(f\"Extracting {file} to Datasets/\")\n",
        "    get_ipython().system(f'7z x {file} -oDatasets/')\n",
        "print(\"Extraction complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Pro.7z to Datasets/\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 3657149 bytes (3572 KiB)\n",
            "\n",
            "Extracting archive: Pro.7z\n",
            "--\n",
            "Path = Pro.7z\n",
            "Type = 7z\n",
            "Physical Size = 3657149\n",
            "Headers Size = 137267\n",
            "Method = LZMA2:16\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b\n",
            "Would you like to replace the existing file:\n",
            "  Path:     Datasets/Pro/1p/1377954818019999562.sgf\n",
            "  Size:     1481 bytes (2 KiB)\n",
            "  Modified: 2018-02-01 20:35:54\n",
            "with the file from archive:\n",
            "  Path:     Pro/1p/1377954818019999562.sgf\n",
            "  Size:     1481 bytes (2 KiB)\n",
            "  Modified: 2018-02-01 20:35:54\n",
            "? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? a\n",
            "\n",
            "  0% 10 - Pro/1p/1377954818019999562.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 1039 - Pro/4p/1493176644019999918.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 1999 - Pro/7p/1428077620019999628.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 2652 - Pro/7p/1477663922019999111.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 3335 - Pro/9p/1485608878019999239.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 3756 - Pro/9p/1500636462019999003.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 4171 - Pro/9p/1501902110019999151.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 4460 - Pro/9p/1502960469019999405.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 4731 - Pro/9p/1503993130019999668.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 4997 - Pro/9p/1504773894019999564.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 5218 - Pro/9p/1505324224019999372.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 5405 - Pro/9p/1505992993019999408.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% 5563 - Pro/9p/1506360020010001916.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 5721 - Pro/9p/1507146220010001560.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 5872 - Pro/9p/1507429115010001928.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 6020 - Pro/9p/1507950412010001564.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 6160 - Pro/9p/1508387277010001568.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 6267 - Pro/9p/1508555737010001743.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 6405 - Pro/9p/1508867423010001096.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 6602 - Pro/9p/1509470155010001395.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 6787 - Pro/9p/1509977947010001933.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 6964 - Pro/9p/1510336549010001023.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 7110 - Pro/9p/1510760280010001151.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 7263 - Pro/9p/1511112170010001693.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 7425 - Pro/9p/1511460320010001385.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 7575 - Pro/9p/1511855947010001660.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% 7719 - Pro/9p/1512195764010001394.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 7863 - Pro/9p/1512585825010001260.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% 7993 - Pro/9p/1512889281010001740.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 8129 - Pro/9p/1513262438010001262.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 8258 - Pro/9p/1513579864010001379.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% 8388 - Pro/9p/1514040870010001298.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 8512 - Pro/9p/1514340970010001027.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 8625 - Pro/9p/1514693262010001525.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 8746 - Pro/9p/1515048753010001838.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 8864 - Pro/9p/1515338963010001658.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 8981 - Pro/9p/1515620537010001829.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 9086 - Pro/9p/1515908477010001808.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 9188 - Pro/9p/1516186329010001770.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 9298 - Pro/9p/1516461521010001159.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 9405 - Pro/9p/1516853018010001895.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 9506 - Pro/9p/1517100996010001044.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 9612 - Pro/9p/1517342255010001095.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 10\n",
            "Files: 9669\n",
            "Size:       14707514\n",
            "Compressed: 3657149\n",
            "Extracting Pro2.7z to Datasets/\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 510585 bytes (499 KiB)\n",
            "\n",
            "Extracting archive: Pro2.7z\n",
            "--\n",
            "Path = Pro2.7z\n",
            "Type = 7z\n",
            "Physical Size = 510585\n",
            "Headers Size = 11744\n",
            "Method = LZMA2:3m\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b\n",
            "Would you like to replace the existing file:\n",
            "  Path:     Datasets/Pro/1p/1530605566010001674.sgf\n",
            "  Size:     941 bytes (1 KiB)\n",
            "  Modified: 2019-10-16 11:23:41\n",
            "with the file from archive:\n",
            "  Path:     Pro/1p/1530605566010001674.sgf\n",
            "  Size:     941 bytes (1 KiB)\n",
            "  Modified: 2019-10-16 11:23:41\n",
            "? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? a\n",
            "\n",
            "  0% 10 - Pro/1p/1530605566010001674.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 308 - Pro/9p/1530660145010001783.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 374 - Pro/9p/1531213666010001554.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 439 - Pro/9p/1537472854010001792.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 503 - Pro/9p/1541248384010001202.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 569 - Pro/9p/1547460483010001613.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  0% 633 - Pro/9p/1554986012010001506.sgf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 10\n",
            "Files: 680\n",
            "Size:       2928899\n",
            "Compressed: 510585\n",
            "Extraction complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from sgfmill import sgf, boards\n",
        "\n",
        "# --- CẤU HÌNH ---\n",
        "DATA_ROOT = './Datasets/Pro/'      # Thư mục gốc chứa 1p, 2p...\n",
        "OUTPUT_DIR = './Datasets/processed/' # Nơi lưu file .npy\n",
        "CHUNK_SIZE = 4000                 # Cứ 2000 ván thì lưu ra 1 file (để tránh tràn RAM)\n",
        "BOARD_SIZE = 19\n",
        "HISTORY_LENGTH = 8            # 8 nước lịch sử\n",
        "\n",
        "# Tạo thư mục output nếu chưa có\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "# --- HÀM HỖ TRỢ (GIỮ NGUYÊN) ---\n",
        "def make_input_planes(game_state, color, history_states):\n",
        "    features = np.zeros((17, BOARD_SIZE, BOARD_SIZE), dtype=np.float32)\n",
        "    current_player_color = color\n",
        "    opponent_color = 'w' if color == 'b' else 'b'\n",
        "\n",
        "    # Lấy lịch sử, đảo ngược để mới nhất lên đầu\n",
        "    recent_states = history_states[-HISTORY_LENGTH:][::-1]\n",
        "\n",
        "    for i, state in enumerate(recent_states):\n",
        "        # 8 kênh Ta\n",
        "        features[i] = (state == current_player_color).astype(np.float32)\n",
        "        # 8 kênh Địch\n",
        "        features[i + 8] = (state == opponent_color).astype(np.float32)\n",
        "\n",
        "    # Kênh 17: Màu quân đi\n",
        "    if color == 'b':\n",
        "        features[16] = np.ones((BOARD_SIZE, BOARD_SIZE), dtype=np.float32)\n",
        "\n",
        "    return features\n",
        "\n",
        "def parse_move(move_coords):\n",
        "    if move_coords is None:\n",
        "        return BOARD_SIZE * BOARD_SIZE # Pass\n",
        "    row, col = move_coords\n",
        "    return row * BOARD_SIZE + col\n",
        "\n",
        "def save_chunk(features, policies, values, chunk_id):\n",
        "    \"\"\"Lưu dữ liệu tạm ra file\"\"\"\n",
        "    print(f\"--> Saving chunk {chunk_id} with {len(features)} moves...\")\n",
        "    np.save(os.path.join(OUTPUT_DIR, f\"features_{chunk_id}.npy\"), np.array(features, dtype=np.float32))\n",
        "    np.save(os.path.join(OUTPUT_DIR, f\"labels_policy_{chunk_id}.npy\"), np.array(policies, dtype=np.int64))\n",
        "    np.save(os.path.join(OUTPUT_DIR, f\"labels_value_{chunk_id}.npy\"), np.array(values, dtype=np.float32))\n",
        "\n",
        "# --- HÀM XỬ LÝ CHÍNH ---\n",
        "def process_all_folders():\n",
        "    # Danh sách folder cần quét (từ 1p đến 9p)\n",
        "    # Nếu tên folder của bạn khác (vd: '1p_games'), hãy sửa lại list này\n",
        "    target_folders = [f\"{i}p\" for i in range(1, 10)]\n",
        "\n",
        "    # Bộ đệm tạm thời\n",
        "    buffer_features = []\n",
        "    buffer_policies = []\n",
        "    buffer_values = []\n",
        "\n",
        "    chunk_counter = 0\n",
        "    total_games_processed = 0\n",
        "\n",
        "    # Duyệt qua từng folder 1p, 2p...\n",
        "    for folder_name in target_folders:\n",
        "        folder_path = os.path.join(DATA_ROOT, folder_name)\n",
        "\n",
        "        # Tìm tất cả file .sgf trong folder này\n",
        "        sgf_files = glob.glob(os.path.join(folder_path, \"*.sgf\"))\n",
        "        print(f\"Processing folder: {folder_name} - Found {len(sgf_files)} files\")\n",
        "\n",
        "        for file_path in sgf_files:\n",
        "            try:\n",
        "                with open(file_path, \"rb\") as f:\n",
        "                    content = f.read()\n",
        "\n",
        "                # SGFmill parse\n",
        "                try:\n",
        "                    game = sgf.Sgf_game.from_bytes(content)\n",
        "                except ValueError:\n",
        "                    continue # Bỏ qua file lỗi\n",
        "\n",
        "                # Lọc dữ liệu: Chỉ lấy 19x19 và không chấp quân\n",
        "                if game.get_size() != 19 or (game.get_handicap() is not None and game.get_handicap() > 0):\n",
        "                    continue\n",
        "\n",
        "                winner = game.get_winner()\n",
        "                if winner is None: continue\n",
        "\n",
        "                # Replay ván đấu\n",
        "                board = boards.Board(19)\n",
        "                current_numpy_board = np.zeros((19, 19), dtype=object)\n",
        "                history_boards = [current_numpy_board.copy()]\n",
        "\n",
        "                for node in game.get_main_sequence():\n",
        "                    color, move_coords = node.get_move()\n",
        "                    if color is None: continue\n",
        "\n",
        "                    # 1. Tạo Feature\n",
        "                    input_tensor = make_input_planes(current_numpy_board, color, history_boards)\n",
        "\n",
        "                    # 2. Tạo Label\n",
        "                    policy_target = parse_move(move_coords)\n",
        "                    value_target = 1.0 if winner == color else -1.0\n",
        "\n",
        "                    # Thêm vào buffer\n",
        "                    buffer_features.append(input_tensor)\n",
        "                    buffer_policies.append(policy_target)\n",
        "                    buffer_values.append(value_target)\n",
        "\n",
        "                    # 3. Apply move cho vòng lặp sau\n",
        "                    if move_coords is not None:\n",
        "                        row, col = move_coords\n",
        "                        board.play(row, col, color)\n",
        "                        # Sync sang numpy\n",
        "                        new_numpy_board = np.zeros((19, 19), dtype=object)\n",
        "                        for r in range(19):\n",
        "                            for c in range(19):\n",
        "                                p = board.get(r, c)\n",
        "                                if p: new_numpy_board[r, c] = p\n",
        "                        current_numpy_board = new_numpy_board\n",
        "\n",
        "                    history_boards.append(current_numpy_board.copy())\n",
        "\n",
        "                total_games_processed += 1\n",
        "\n",
        "                # CƠ CHẾ CHUNKING: Kiểm tra nếu buffer đầy thì lưu\n",
        "                # Ở đây ta check theo số ván (game), hoặc số moves\n",
        "                # Nếu buffer đạt khoảng 100.000 mẫu (moves) thì lưu là vừa đẹp\n",
        "                if len(buffer_features) >= 50000: # Khoảng 200-300 ván\n",
        "                    save_chunk(buffer_features, buffer_policies, buffer_values, chunk_counter)\n",
        "                    chunk_counter += 1\n",
        "                    # Reset buffer để giải phóng RAM\n",
        "                    buffer_features = []\n",
        "                    buffer_policies = []\n",
        "                    buffer_values = []\n",
        "                    print(f\"Cleared RAM. Total games so far: {total_games_processed}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Skipping file {file_path}: {e}\")\n",
        "\n",
        "    # Lưu nốt phần còn lại trong buffer (nếu có)\n",
        "    if len(buffer_features) > 0:\n",
        "        save_chunk(buffer_features, buffer_policies, buffer_values, chunk_counter)\n",
        "\n",
        "    print(f\"=== COMPLETED ===\")\n",
        "    print(f\"Total games processed: {total_games_processed}\")\n",
        "    print(f\"Data saved to: {OUTPUT_DIR}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_all_folders()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zLp5gDqcFkL",
        "outputId": "7f1b4b5b-5a23-4610-b604-3ecbab784e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing folder: 1p - Found 337 files\n",
            "--> Saving chunk 0 with 50108 moves...\n",
            "Cleared RAM. Total games so far: 267\n",
            "Processing folder: 2p - Found 224 files\n",
            "Skipping file ./Datasets/Pro/2p/1384432811019999870.sgf: \n",
            "Processing folder: 3p - Found 474 files\n",
            "Skipping file ./Datasets/Pro/3p/1440209016019999364.sgf: \n",
            "--> Saving chunk 1 with 50126 moves...\n",
            "Cleared RAM. Total games so far: 531\n",
            "Skipping file ./Datasets/Pro/3p/1503025471019999928.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1489043325019999769.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1487833529019999156.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1490862288019999897.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1550747182010001738.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1491466159019999355.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1500612367019999290.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1482114863019999178.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1500519692019999167.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1491985248019999753.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1489648230019999778.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1482997173019999279.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1441251931019999518.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1439819361019999462.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1490324760019999121.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1488438066019999876.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1440427304019999648.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1439608752019999521.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1440641280019999977.sgf: \n",
            "--> Saving chunk 2 with 50094 moves...\n",
            "Cleared RAM. Total games so far: 780\n",
            "Skipping file ./Datasets/Pro/3p/1437406668019999606.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1502074355019999978.sgf: \n",
            "Skipping file ./Datasets/Pro/3p/1388816331019999246.sgf: \n",
            "Processing folder: 4p - Found 311 files\n",
            "Skipping file ./Datasets/Pro/4p/1557401525010001679.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1556197570010001975.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1513751797010001440.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1513754930010001780.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1494233966019999998.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1552468713010001530.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1513579794010001257.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1499655389019999671.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1499929079019999035.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1494840076019999593.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1513666201010001886.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1496304082019999694.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1499829675019999050.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1508482168010001670.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1513596582010001078.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1492949752019999218.sgf: \n",
            "--> Saving chunk 3 with 50068 moves...\n",
            "Cleared RAM. Total games so far: 1023\n",
            "Skipping file ./Datasets/Pro/4p/1497864632019999341.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1494160824019999401.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1509967696010001996.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1505723975019999792.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1492343506019999419.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1495445077019999477.sgf: \n",
            "Skipping file ./Datasets/Pro/4p/1508157554010001419.sgf: \n",
            "Processing folder: 5p - Found 258 files\n",
            "Skipping file ./Datasets/Pro/5p/1424747211019999142.sgf: \n",
            "Skipping file ./Datasets/Pro/5p/1424525405019999058.sgf: \n",
            "--> Saving chunk 4 with 50109 moves...\n",
            "Cleared RAM. Total games so far: 1275\n",
            "Skipping file ./Datasets/Pro/5p/1424661667019999118.sgf: \n",
            "Processing folder: 6p - Found 391 files\n",
            "Skipping file ./Datasets/Pro/6p/1384352797019999019.sgf: \n",
            "--> Saving chunk 5 with 50107 moves...\n",
            "Cleared RAM. Total games so far: 1522\n",
            "Skipping file ./Datasets/Pro/6p/1384446162019999481.sgf: \n",
            "Skipping file ./Datasets/Pro/6p/1389183603019999816.sgf: \n",
            "Processing folder: 7p - Found 962 files\n",
            "--> Saving chunk 6 with 50081 moves...\n",
            "Cleared RAM. Total games so far: 1776\n",
            "Skipping file ./Datasets/Pro/7p/1454051203019999946.sgf: \n",
            "Skipping file ./Datasets/Pro/7p/1433561074019999479.sgf: \n",
            "Skipping file ./Datasets/Pro/7p/1433061864019999410.sgf: \n",
            "--> Saving chunk 7 with 50008 moves...\n",
            "Cleared RAM. Total games so far: 2035\n",
            "Skipping file ./Datasets/Pro/7p/1550652117010001701.sgf: \n",
            "Skipping file ./Datasets/Pro/7p/1433559314019999343.sgf: \n",
            "Skipping file ./Datasets/Pro/7p/1434290609019999400.sgf: \n",
            "--> Saving chunk 8 with 50082 moves...\n",
            "Cleared RAM. Total games so far: 2292\n",
            "Skipping file ./Datasets/Pro/7p/1425700418019999463.sgf: \n",
            "--> Saving chunk 9 with 50031 moves...\n",
            "Cleared RAM. Total games so far: 2553\n",
            "Processing folder: 8p - Found 406 files\n",
            "--> Saving chunk 10 with 50132 moves...\n",
            "Cleared RAM. Total games so far: 2802\n",
            "--> Saving chunk 11 with 50193 moves...\n",
            "Cleared RAM. Total games so far: 3056\n",
            "Processing folder: 9p - Found 6985 files\n",
            "--> Saving chunk 12 with 50073 moves...\n",
            "Cleared RAM. Total games so far: 3287\n",
            "--> Saving chunk 13 with 50178 moves...\n",
            "Cleared RAM. Total games so far: 3528\n",
            "Skipping file ./Datasets/Pro/9p/1379606328019999393.sgf: \n",
            "--> Saving chunk 14 with 50138 moves...\n",
            "Cleared RAM. Total games so far: 3764\n",
            "--> Saving chunk 15 with 33831 moves...\n",
            "=== COMPLETED ===\n",
            "Total games processed: 3923\n",
            "Data saved to: ./Datasets/processed/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, num_filters=128):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(num_filters)\n",
        "        self.conv2 = nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(num_filters)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += residual\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class GoResNet(nn.Module):\n",
        "    def __init__(self, num_blocks=10, num_filters=128):\n",
        "        super(GoResNet, self).__init__()\n",
        "        self.conv_input = nn.Sequential(\n",
        "            nn.Conv2d(17, num_filters, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.res_blocks = nn.ModuleList([ResidualBlock(num_filters) for _ in range(num_blocks)])\n",
        "\n",
        "        # Policy Head\n",
        "        self.policy_head = nn.Sequential(\n",
        "            nn.Conv2d(num_filters, 2, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(2),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2 * 19 * 19, 362)\n",
        "        )\n",
        "\n",
        "        # Value Head\n",
        "        self.value_head = nn.Sequential(\n",
        "            nn.Conv2d(num_filters, 1, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(19 * 19, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_input(x)\n",
        "        for block in self.res_blocks:\n",
        "            x = block(x)\n",
        "        policy = self.policy_head(x)\n",
        "        value = self.value_head(x)\n",
        "        return policy, value"
      ],
      "metadata": {
        "id": "UXsyCZ3me6iB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, ConcatDataset\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "class GoChunkDataset(Dataset):\n",
        "    def __init__(self, feature_path, policy_path, value_path):\n",
        "        # mmap_mode='r' cực kỳ quan trọng trên Colab để không tràn RAM\n",
        "        self.features = np.load(feature_path, mmap_mode='r')\n",
        "        self.policies = np.load(policy_path, mmap_mode='r')\n",
        "        self.values = np.load(value_path, mmap_mode='r')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # .copy() để chuyển data từ ổ cứng vào RAM\n",
        "        return {\n",
        "            'feature': torch.tensor(self.features[idx].copy(), dtype=torch.float32),\n",
        "            'policy_target': torch.tensor(self.policies[idx].copy(), dtype=torch.long),\n",
        "            'value_target': torch.tensor(self.values[idx].copy(), dtype=torch.float32)\n",
        "        }\n",
        "\n",
        "def get_dataset(data_dir):\n",
        "    # Lưu ý: data_dir trên Colab sẽ là '/content/dataset'\n",
        "    feature_files = sorted(glob.glob(os.path.join(data_dir, \"features_*.npy\")))\n",
        "    datasets = []\n",
        "    print(f\"Scanning chunks in {data_dir}...\")\n",
        "\n",
        "    for f_path in feature_files:\n",
        "        try:\n",
        "            filename = os.path.basename(f_path)\n",
        "            # Giả sử format tên file là features_{id}.npy\n",
        "            chunk_id = filename.split('_')[1].split('.')[0]\n",
        "\n",
        "            p_path = os.path.join(data_dir, f\"labels_policy_{chunk_id}.npy\")\n",
        "            v_path = os.path.join(data_dir, f\"labels_value_{chunk_id}.npy\")\n",
        "\n",
        "            if os.path.exists(p_path) and os.path.exists(v_path):\n",
        "                ds = GoChunkDataset(f_path, p_path, v_path)\n",
        "                datasets.append(ds)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading chunk {f_path}: {e}\")\n",
        "\n",
        "    if not datasets:\n",
        "        raise RuntimeError(\"No dataset found!\")\n",
        "\n",
        "    print(f\"Loaded {len(datasets)} chunks.\")\n",
        "    return ConcatDataset(datasets)"
      ],
      "metadata": {
        "id": "DJGvbNPZfDTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMBy0bijqbMr",
        "outputId": "914a2860-b3a0-4209-b0c7-174a74b0dba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FOR FINETUNE ONLY"
      ],
      "metadata": {
        "id": "Srb0Qu2yrUd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# --- CẤU HÌNH FINE-TUNE ---\n",
        "PRETRAINED_PATH = \"/content/go_model_epoch_10.pth\" # Model cũ\n",
        "NEW_DATA_DIR = \"/content/Datasets/processed\" # Folder chứa dataset mới (dạng .npy)\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 5               # Fine-tune thường cần ít epoch hơn train mới\n",
        "LEARNING_RATE = 0.0005   # <--- QUAN TRỌNG: Giảm nhỏ hơn lúc train gốc (thường là 1/10)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def fine_tune():\n",
        "    print(f\"Fine-tuning on device: {DEVICE}\")\n",
        "\n",
        "    # 1. Khởi tạo kiến trúc mạng\n",
        "    # LƯU Ý: num_blocks và num_filters PHẢI GIỐNG HỆT lúc train model cũ\n",
        "    model = GoResNet(num_blocks=10, num_filters=128).to(DEVICE)\n",
        "\n",
        "    # 2. Load trọng số cũ (Weights)\n",
        "    print(f\"Loading weights from {PRETRAINED_PATH}...\")\n",
        "    try:\n",
        "        # map_location để đảm bảo load được dù train trên GPU khác hay CPU\n",
        "        state_dict = torch.load(PRETRAINED_PATH, map_location=DEVICE)\n",
        "        model.load_state_dict(state_dict)\n",
        "        print(\"Weights loaded successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading weights: {e}\")\n",
        "        return\n",
        "\n",
        "    # 3. Chuẩn bị dữ liệu mới\n",
        "    # Dùng hàm get_dataset cũ nhưng trỏ vào folder dữ liệu mới\n",
        "    dataset = get_dataset(NEW_DATA_DIR)\n",
        "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "    # 4. Optimizer với Learning Rate thấp\n",
        "    criterion_policy = nn.CrossEntropyLoss()\n",
        "    criterion_value = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE) # LR nhỏ\n",
        "\n",
        "    # 5. Vòng lặp Training (như cũ)\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        print(f\"Start Fine-tuning Epoch {epoch+1}...\")\n",
        "\n",
        "        for batch_idx, batch in enumerate(dataloader):\n",
        "            features = batch['feature'].to(DEVICE)\n",
        "            target_policy = batch['policy_target'].to(DEVICE)\n",
        "            target_value = batch['value_target'].to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            pred_policy, pred_value = model(features)\n",
        "\n",
        "            loss_p = criterion_policy(pred_policy, target_policy)\n",
        "            loss_v = criterion_value(pred_value.squeeze(), target_value)\n",
        "            loss = loss_p + loss_v\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f\"  Batch {batch_idx} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "        # Lưu model fine-tune với tên mới\n",
        "        save_path = f\"/content/finetuned_epoch_{epoch+1}.pth\"\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"Saved finetuned model: {save_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    fine_tune()"
      ],
      "metadata": {
        "id": "18GIVMAorYCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ccbe180-7335-4349-b397-1fbbf8c2dbb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning on device: cuda\n",
            "Loading weights from /content/go_model_epoch_10.pth...\n",
            "Weights loaded successfully!\n",
            "Scanning chunks in /content/Datasets/processed...\n",
            "Loaded 16 chunks.\n",
            "Start Fine-tuning Epoch 1...\n",
            "  Batch 0 | Loss: 1.9907\n",
            "  Batch 100 | Loss: 1.5917\n",
            "  Batch 200 | Loss: 1.6675\n",
            "  Batch 300 | Loss: 1.6041\n",
            "  Batch 400 | Loss: 1.7238\n",
            "  Batch 500 | Loss: 1.6227\n",
            "  Batch 600 | Loss: 1.6054\n",
            "  Batch 700 | Loss: 1.5275\n",
            "  Batch 800 | Loss: 1.7691\n",
            "  Batch 900 | Loss: 1.6065\n",
            "  Batch 1000 | Loss: 1.5352\n",
            "  Batch 1100 | Loss: 1.6819\n",
            "  Batch 1200 | Loss: 1.7083\n",
            "  Batch 1300 | Loss: 1.6519\n",
            "  Batch 1400 | Loss: 1.7216\n",
            "  Batch 1500 | Loss: 1.7969\n",
            "  Batch 1600 | Loss: 1.5229\n",
            "  Batch 1700 | Loss: 1.5906\n",
            "  Batch 1800 | Loss: 1.5065\n",
            "  Batch 1900 | Loss: 1.6926\n",
            "  Batch 2000 | Loss: 1.6820\n",
            "  Batch 2100 | Loss: 1.6777\n",
            "  Batch 2200 | Loss: 1.6556\n",
            "  Batch 2300 | Loss: 1.7864\n",
            "  Batch 2400 | Loss: 1.6376\n",
            "  Batch 2500 | Loss: 1.4332\n",
            "  Batch 2600 | Loss: 1.6660\n",
            "  Batch 2700 | Loss: 1.7176\n",
            "  Batch 2800 | Loss: 1.6053\n",
            "  Batch 2900 | Loss: 1.7654\n",
            "  Batch 3000 | Loss: 1.8630\n",
            "Saved finetuned model: /content/finetuned_epoch_1.pth\n",
            "Start Fine-tuning Epoch 2...\n",
            "  Batch 0 | Loss: 1.4464\n",
            "  Batch 100 | Loss: 1.3834\n",
            "  Batch 200 | Loss: 1.4440\n",
            "  Batch 300 | Loss: 1.4233\n",
            "  Batch 400 | Loss: 1.2834\n",
            "  Batch 500 | Loss: 1.5348\n",
            "  Batch 600 | Loss: 1.5985\n",
            "  Batch 700 | Loss: 1.4888\n",
            "  Batch 800 | Loss: 1.4642\n",
            "  Batch 900 | Loss: 1.4391\n",
            "  Batch 1000 | Loss: 1.7218\n",
            "  Batch 1100 | Loss: 1.5794\n",
            "  Batch 1200 | Loss: 1.3190\n",
            "  Batch 1300 | Loss: 1.5612\n",
            "  Batch 1400 | Loss: 1.6000\n",
            "  Batch 1500 | Loss: 1.4999\n",
            "  Batch 1600 | Loss: 1.5517\n",
            "  Batch 1700 | Loss: 1.4782\n",
            "  Batch 1800 | Loss: 1.3977\n",
            "  Batch 1900 | Loss: 1.5925\n",
            "  Batch 2000 | Loss: 1.5033\n",
            "  Batch 2100 | Loss: 1.5772\n",
            "  Batch 2200 | Loss: 1.6538\n",
            "  Batch 2300 | Loss: 1.9869\n",
            "  Batch 2400 | Loss: 1.7035\n",
            "  Batch 2500 | Loss: 1.5778\n",
            "  Batch 2600 | Loss: 1.4917\n",
            "  Batch 2700 | Loss: 1.6623\n",
            "  Batch 2800 | Loss: 1.5791\n",
            "  Batch 2900 | Loss: 1.5570\n",
            "  Batch 3000 | Loss: 1.6072\n",
            "Saved finetuned model: /content/finetuned_epoch_2.pth\n",
            "Start Fine-tuning Epoch 3...\n",
            "  Batch 0 | Loss: 1.1697\n",
            "  Batch 100 | Loss: 1.2365\n",
            "  Batch 200 | Loss: 1.3669\n",
            "  Batch 300 | Loss: 1.5481\n",
            "  Batch 400 | Loss: 1.3991\n",
            "  Batch 500 | Loss: 1.4819\n",
            "  Batch 600 | Loss: 1.5570\n",
            "  Batch 700 | Loss: 1.4170\n",
            "  Batch 800 | Loss: 1.4756\n",
            "  Batch 900 | Loss: 1.4393\n",
            "  Batch 1000 | Loss: 1.4465\n",
            "  Batch 1100 | Loss: 1.4857\n",
            "  Batch 1200 | Loss: 1.5380\n",
            "  Batch 1300 | Loss: 1.4560\n",
            "  Batch 1400 | Loss: 1.4675\n",
            "  Batch 1500 | Loss: 1.5221\n",
            "  Batch 1600 | Loss: 1.4628\n",
            "  Batch 1700 | Loss: 1.3051\n",
            "  Batch 1800 | Loss: 1.5202\n",
            "  Batch 1900 | Loss: 1.5238\n",
            "  Batch 2000 | Loss: 1.4175\n",
            "  Batch 2100 | Loss: 1.4253\n",
            "  Batch 2200 | Loss: 1.3960\n",
            "  Batch 2300 | Loss: 1.4820\n",
            "  Batch 2400 | Loss: 1.4308\n",
            "  Batch 2500 | Loss: 1.5223\n",
            "  Batch 2600 | Loss: 1.5225\n",
            "  Batch 2700 | Loss: 1.6517\n",
            "  Batch 2800 | Loss: 1.7788\n",
            "  Batch 2900 | Loss: 1.5226\n",
            "  Batch 3000 | Loss: 1.4508\n",
            "Saved finetuned model: /content/finetuned_epoch_3.pth\n",
            "Start Fine-tuning Epoch 4...\n",
            "  Batch 0 | Loss: 1.4109\n",
            "  Batch 100 | Loss: 1.3846\n",
            "  Batch 200 | Loss: 1.2765\n",
            "  Batch 300 | Loss: 1.3692\n",
            "  Batch 400 | Loss: 1.1973\n",
            "  Batch 500 | Loss: 1.3306\n",
            "  Batch 600 | Loss: 1.3879\n",
            "  Batch 700 | Loss: 1.2733\n",
            "  Batch 800 | Loss: 1.3065\n",
            "  Batch 900 | Loss: 1.2275\n",
            "  Batch 1000 | Loss: 1.3043\n",
            "  Batch 1100 | Loss: 1.2767\n",
            "  Batch 1200 | Loss: 1.2804\n",
            "  Batch 1300 | Loss: 1.3255\n",
            "  Batch 1400 | Loss: 1.1492\n",
            "  Batch 1500 | Loss: 1.1434\n",
            "  Batch 1600 | Loss: 1.5075\n",
            "  Batch 1700 | Loss: 1.5236\n",
            "  Batch 1800 | Loss: 1.1871\n",
            "  Batch 1900 | Loss: 1.3145\n",
            "  Batch 2000 | Loss: 1.5234\n",
            "  Batch 2100 | Loss: 1.3270\n",
            "  Batch 2200 | Loss: 1.5238\n",
            "  Batch 2300 | Loss: 1.3146\n",
            "  Batch 2400 | Loss: 1.4656\n",
            "  Batch 2500 | Loss: 1.3046\n",
            "  Batch 2600 | Loss: 1.5876\n",
            "  Batch 2700 | Loss: 1.5572\n",
            "  Batch 2800 | Loss: 1.3081\n",
            "  Batch 2900 | Loss: 1.4336\n",
            "  Batch 3000 | Loss: 1.3971\n",
            "Saved finetuned model: /content/finetuned_epoch_4.pth\n",
            "Start Fine-tuning Epoch 5...\n",
            "  Batch 0 | Loss: 1.0751\n",
            "  Batch 100 | Loss: 1.1174\n",
            "  Batch 200 | Loss: 1.2456\n",
            "  Batch 300 | Loss: 1.2947\n",
            "  Batch 400 | Loss: 1.2487\n",
            "  Batch 500 | Loss: 1.0675\n",
            "  Batch 600 | Loss: 1.1114\n",
            "  Batch 700 | Loss: 1.2830\n",
            "  Batch 800 | Loss: 1.1279\n",
            "  Batch 900 | Loss: 1.3255\n",
            "  Batch 1000 | Loss: 1.2627\n",
            "  Batch 1100 | Loss: 1.2623\n",
            "  Batch 1200 | Loss: 1.2079\n",
            "  Batch 1300 | Loss: 1.4354\n",
            "  Batch 1400 | Loss: 1.2804\n",
            "  Batch 1500 | Loss: 1.2618\n",
            "  Batch 1600 | Loss: 1.2762\n",
            "  Batch 1700 | Loss: 1.2494\n",
            "  Batch 1800 | Loss: 1.3311\n",
            "  Batch 1900 | Loss: 1.4480\n",
            "  Batch 2000 | Loss: 1.4044\n",
            "  Batch 2100 | Loss: 1.3839\n",
            "  Batch 2200 | Loss: 1.3989\n",
            "  Batch 2300 | Loss: 1.4150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.onnx\n",
        "from model import GoResNet  # Import kiến trúc mạng đã định nghĩa\n",
        "import os\n",
        "\n",
        "# --- CẤU HÌNH ---\n",
        "# Đường dẫn file model PyTorch đã train xong\n",
        "INPUT_MODEL_PATH = \"go_model_epoch_10.pth\"\n",
        "# Tên file ONNX đầu ra\n",
        "OUTPUT_ONNX_PATH = \"GoModel.onnx\"\n",
        "# Cấu trúc mạng (Phải khớp y hệt lúc train)\n",
        "NUM_BLOCKS = 10\n",
        "NUM_FILTERS = 128\n",
        "\n",
        "def export_model():\n",
        "    print(f\"Preparing to export {INPUT_MODEL_PATH} to ONNX...\")\n",
        "\n",
        "    # 1. Khởi tạo model và load trọng số\n",
        "    device = torch.device(\"cpu\") # Export nên thực hiện trên CPU để tránh lỗi tương thích\n",
        "    model = GoResNet(num_blocks=NUM_BLOCKS, num_filters=NUM_FILTERS)\n",
        "\n",
        "    if not os.path.exists(INPUT_MODEL_PATH):\n",
        "        print(f\"Error: File {INPUT_MODEL_PATH} not found!\")\n",
        "        return\n",
        "\n",
        "    # Load weights (map_location='cpu' đảm bảo chạy được dù train trên GPU)\n",
        "    state_dict = torch.load(INPUT_MODEL_PATH, map_location=device)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.to(device)\n",
        "    model.eval() # Quan trọng: Chuyển sang chế độ Inference (tắt Dropout, Batch Norm cố định)\n",
        "\n",
        "    # 2. Tạo Input giả lập (Dummy Input)\n",
        "    # Kích thước: [Batch=1, Channels=17, Height=19, Width=19]\n",
        "    dummy_input = torch.randn(1, 17, 19, 19, requires_grad=True).to(device)\n",
        "\n",
        "    # 3. Thực hiện Export\n",
        "    # Torch sẽ \"chạy thử\" dummy_input qua mạng để ghi lại biểu đồ tính toán\n",
        "    torch.onnx.export(\n",
        "        model,                      # Model cần export\n",
        "        dummy_input,                # Input mẫu\n",
        "        OUTPUT_ONNX_PATH,           # Tên file đầu ra\n",
        "        export_params=True,         # Lưu cả trọng số (weights) vào file\n",
        "        opset_version=11,           # Version 11 hoặc 12 tương thích tốt nhất với .NET\n",
        "        do_constant_folding=True,   # Tối ưu hóa các hằng số\n",
        "        input_names=['input'],      # [QUAN TRỌNG] Tên biến đầu vào để C# gọi\n",
        "        output_names=['policy', 'value'], # [QUAN TRỌNG] Tên biến đầu ra để C# nhận\n",
        "        dynamic_axes={\n",
        "            'input': {0: 'batch_size'},  # Cho phép Batch Size thay đổi (không cố định là 1)\n",
        "            'policy': {0: 'batch_size'},\n",
        "            'value': {0: 'batch_size'}\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(f\"✅ Success! Model exported to: {OUTPUT_ONNX_PATH}\")\n",
        "    print(\"You can now import this file into your .NET backend.\")\n",
        "\n",
        "# --- PHẦN KIỂM TRA LẠI (VERIFY) ---\n",
        "def verify_onnx():\n",
        "    \"\"\"Chạy thử model ONNX bằng Python để đảm bảo nó không bị lỗi\"\"\"\n",
        "    try:\n",
        "        import onnxruntime as ort\n",
        "        import numpy as np\n",
        "\n",
        "        print(\"\\nVerifying ONNX model...\")\n",
        "        # Tạo session\n",
        "        ort_session = ort.InferenceSession(OUTPUT_ONNX_PATH)\n",
        "\n",
        "        # Tạo input ngẫu nhiên (numpy)\n",
        "        x = np.random.randn(1, 17, 19, 19).astype(np.float32)\n",
        "\n",
        "        # Chạy inference\n",
        "        outputs = ort_session.run(\n",
        "            None, # Lấy tất cả output\n",
        "            {'input': x} # Map input name\n",
        "        )\n",
        "\n",
        "        policy, value = outputs\n",
        "        print(f\"Verification Input Shape: {x.shape}\")\n",
        "        print(f\"Output Policy Shape: {policy.shape} (Expect 1, 362)\")\n",
        "        print(f\"Output Value Shape: {value.shape} (Expect 1, 1)\")\n",
        "        print(\"✅ Verification Passed! The ONNX model works.\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"Warning: 'onnxruntime' library not found. Skipping verification.\")\n",
        "        print(\"Run `pip install onnxruntime` to verify.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    export_model()\n",
        "    verify_onnx()"
      ],
      "metadata": {
        "id": "jQ7RuQ21Axq5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}